
<!-- @import "[TOC]" {cmd="toc" depthFrom=1 depthTo=6 orderedList=false} -->

<!-- code_chunk_output -->

- [TCP](#tcp)
  - [TCP 和 UDP 的区别](#tcp-和-udp-的区别)
  - [TCP 三次握手的过程](#tcp-三次握手的过程)
    - [为什么不是两次？](#为什么不是两次)
    - [为什么不是四次？](#为什么不是四次)
    - [携带数据](#携带数据)
    - [同时打开会怎样](#同时打开会怎样)
  - [TCP 四次挥手的过程](#tcp-四次挥手的过程)
    - [为什么是四次挥手而不是三次](#为什么是四次挥手而不是三次)
    - [等待2MSL的意义](#等待2msl的意义)
    - [SYN Flood 攻击](#syn-flood-攻击)
      - [SYN Flood 攻击原理](#syn-flood-攻击原理)
      - [如何应对 SYN Flood 攻击](#如何应对-syn-flood-攻击)
  - [TCP 快速打开的原理](#tcp-快速打开的原理)
    - [流程](#流程)
    - [TFO 的优势](#tfo-的优势)
  - [超时重传机制](#超时重传机制)
    - [经典方法](#经典方法)
    - [标准方法](#标准方法)
  - [流量控制](#流量控制)
- [http](#http)
  - [报文结构](#报文结构)
  - [请求方法](#请求方法)
  - [URI](#uri)
    - [编码](#编码)
  - [状态码](#状态码)
  - [性质和缺点](#性质和缺点)
    - [HTTP 特点](#http-特点)
    - [HTTP 缺点](#http-缺点)
  - [Accept系列字段](#accept系列字段)
  - [传输](#传输)
  - [处理表单数据的提交](#处理表单数据的提交)
  - [队头阻塞问题](#队头阻塞问题)
    - [解决方案](#解决方案)
  - [Cookie](#cookie)
    - [生存周期](#生存周期)
    - [作用域](#作用域)
    - [安全相关](#安全相关)
    - [Cookie的缺点](#cookie的缺点)
  - [HTTP 代理](#http-代理)
    - [代理服务器的功能](#代理服务器的功能)
    - [相关头部字段](#相关头部字段)
- [浏览器相关](#浏览器相关)
  - [V8的优化](#v8的优化)
    - [parse的执行流程](#parse的执行流程)
    - [JIT混合引擎](#jit混合引擎)
    - [JIT具体流程](#jit具体流程)
  - [references](#references)

<!-- /code_chunk_output -->

# TCP
## TCP 和 UDP 的区别
基本的区别:
- TCP是一个面向连接的、可靠的、基于字节流的传输层协议。
- 而UDP是一个面向无连接的传输层协议。(就这么简单，其它TCP的特性也就没有了)。

具体来分析，和 UDP 相比，TCP 有三大核心特性:
**面向连接**
所谓的连接，指的是客户端和服务器的连接，在双方互相通信之前，TCP 需要三次握手建立连接，而 UDP 没有相应建立连接的过程。

**可靠性**
TCP 花了非常多的功夫保证连接的可靠，这个可靠性体现在哪些方面呢？一个是有状态，另一个是可控制。

TCP 会精准记录哪些数据发送了，哪些数据被对方接收了，哪些没有被接收到，而且保证数据包按序到达，不允许半点差错。这是有状态。
当意识到丢包了或者网络环境不佳，TCP 会根据具体情况调整自己的行为，控制自己的发送速度或者重发。这是可控制。
相应的，UDP 就是无状态, 不可控的。

**面向字节流。**
UDP 的数据传输是基于数据报的，这是因为仅仅只是继承了 IP 层的特性，而 TCP 为了维护状态，将一个个 IP 包变成了字节流。

## TCP 三次握手的过程
TCP 的三次握手，主要是建立连接的时候，为了确认双方的两样能力: 发送的能力和接收的能力。

![Screen Shot 2021-08-27 at 14.28.31](/assets/Screen%20Shot%202021-08-27%20at%2014.28.31.png)

- 最开始双方都处于CLOSED状态。
- 服务端开始监听某个端口，进入了LISTEN状态。
- 客户端主动发起连接，发送 SYN , 自己变成了SYN-SENT状态。 （第一次握手）
- 服务端接收到，返回SYN和ACK(对应客户端发来的SYN)，自己变成了SYN-REVD。（第二次握手）
- 之后客户端再发送ACK给服务端，自己变成了ESTABLISHED状态；（第三次握手）
- 服务端收到ACK之后，也变成了ESTABLISHED状态。

另外需要注意的是，从图中可以看出，SYN 是需要消耗一个序列号的，下次发送对应的 ACK 序列号要加1，为什么呢？只需要记住一个规则: 凡是需要对端确认的，一定消耗TCP报文的序列号。

SYN 需要对端的确认， 而 ACK 并不需要，因此 SYN 消耗一个序列号而 ACK 不需要。

### 为什么不是两次？
因为无法确认客户端的接收能力。握手的目的是：确实客户端和服务端都有发送和接收的能力。

- 第一次握手：（确认客户端发送的能力）
- 第二次握手：（确认服务端接收和发送的能力）
- 第三次握手：（确认客户端接收的能力）

### 为什么不是四次？
因为三次已经确认完毕了，之后没有其它东西需要确认，再多握手也是浪费。

### 携带数据
前两次握手不能携带数据，第三次握手的时候可以携带。

如果前两次握手能够携带数据，那么一旦有人想攻击服务器，那么他只需要在第一次握手中的 SYN 报文中放大量数据，那么服务器势必会消耗更多的时间和内存空间去处理这些数据，增大了服务器被攻击的风险。

第三次握手的时候，客户端已经处于ESTABLISHED状态，并且已经能够确认服务器的接收、发送能力正常，这个时候相对安全了，可以携带数据。

### 同时打开会怎样
- 在发送方给接收方发SYN报文的同时，接收方也给发送方发SYN报文
- 发完SYN，两者的状态都变为SYN-SENT。
- 在各自收到对方的SYN后，两者状态都变为SYN-REVD。
- 接着会回复对应的ACK + SYN，这个报文在对方接收之后，两者状态一起变为ESTABLISHED。

![Screen Shot 2021-08-27 at 14.34.52](/assets/Screen%20Shot%202021-08-27%20at%2014.34.52.png)

## TCP 四次挥手的过程
断开连接需要四次握手，多的一次其实就是第二次握手，服务端要发两个报文回来。

![Screen Shot 2021-08-27 at 14.36.23](/assets/Screen%20Shot%202021-08-27%20at%2014.36.23.png)

- 刚开始双方处于ESTABLISHED状态。
- 客户端要断开了，向服务器发送 FIN 报文
- 发送后客户端变成了FIN-WAIT-1状态。注意, 这时候客户端同时也变成了half-close(半关闭)状态，即无法向服务端发送报文，只能接收。
- 服务端接收后向客户端确认，变成了CLOSED-WAIT状态。
- 客户端接收到了服务端的确认，变成了FIN-WAIT2状态。
- 随后，服务端向客户端发送FIN，自己进入LAST-ACK状态，
- 客户端收到服务端发来的FIN后，自己变成了TIME-WAIT状态，然后发送 ACK 给服务端。注意了，这个时候，客户端需要等待足够长的时间，具体来说，是 2 个 MSL(Maximum Segment Lifetime，报文最大生存时间), 在这段时间内如果客户端没有收到服务端的重发请求，那么表示 ACK 成功到达，挥手结束，否则客户端重发 ACK。

### 为什么是四次挥手而不是三次
主要是为什么服务端要先返回ACK，然后再返回FIN ACK，而不能一起发。这是因为，服务端要等待所有的报文都发送完毕了，才能发FIN ACK。也就是说，关闭之前要处理完事情，所以关闭是一个过程：
- ACK就是说“我在准备关闭了”
- FIN ACK就是说，“我已经准备好了，随时可以关闭”。

如果把ACK延迟到FIN ACK再发送，那客户端如果等久了，可能会重复发送FIN过来。先发一个ACK意思就是告诉客户端，我在做事了，别急。

### 等待2MSL的意义
就是确保如果有什么意外的话，能收到消息，也就是留出一来一回的时间：
- 1 个 MSL 确保四次挥手中主动关闭方最后的 ACK 报文最终能达到对端
- 1 个 MSL 确保对端没有收到 ACK 重传的 FIN 报文可以到达

### SYN Flood 攻击
三次握手前，服务端的状态从CLOSED变为LISTEN, 同时在内部创建了两个队列：半连接队列（SYN队列）和全连接队列（ACCEPT队列）。

**半连接队列**
当客户端发送SYN到服务端，服务端收到以后回复ACK和SYN，状态由LISTEN变为SYN_RCVD，此时这个连接就被推入了SYN队列，也就是半连接队列。

**全连接队列**
当客户端返回ACK, 服务端接收后，三次握手完成。这个时候连接等待被具体的应用取走，在被取走之前，它会被推入另外一个 TCP 维护的队列，也就是全连接队列(Accept Queue)。

#### SYN Flood 攻击原理
SYN Flood 属于典型的 DoS/DDoS 攻击。其攻击的原理很简单，就是用客户端在短时间内伪造大量不存在的 IP 地址，并向服务端疯狂发送SYN。对于服务端而言，会产生两个危险的后果:

- 处理大量的SYN包并返回对应ACK, 势必有大量连接处于SYN_RCVD状态，从而占满整个半连接队列，无法处理正常的请求。
- 由于是不存在的 IP，服务端长时间收不到客户端的ACK，会导致服务端不断重发数据，直到耗尽服务端的资源。

#### 如何应对 SYN Flood 攻击
- 增加 SYN 连接，也就是增加半连接队列的容量。
- 减少 SYN + ACK 重试次数，避免大量的超时重发。
- 利用 SYN Cookie 技术，在服务端接收到SYN后不立即分配连接资源，而是根据这个SYN计算出一个Cookie，连同第二次握手回复给客户端，在客户端回复ACK的时候带上这个Cookie值，服务端验证 Cookie 合法之后才分配连接资源。

##  TCP 快速打开的原理
每次都三次握手好麻烦，可以优化成利用SYN Cookie 的TCP 快速打开(TCP Fast Open, 即TFO)。

![Screen Shot 2021-08-27 at 15.42.33](/assets/Screen%20Shot%202021-08-27%20at%2015.42.33.png)

### 流程
首轮三次握手：
- 首先客户端发送SYN给服务端，服务端接收到。
- 服务端不是立刻回复 SYN + ACK，而是通过计算得到一个SYN Cookie, 将这个Cookie放到 TCP 报文的 Fast Open选项中，然后才给客户端返回。
- 客户端拿到这个 Cookie 的值缓存下来。后面正常完成三次握手。

后面的三次握手：
- 客户端会将之前缓存的 Cookie、SYN 和HTTP请求发送给服务端
- 服务端验证了 Cookie 的合法性，如果不合法直接丢弃；如果是合法的，那么就正常返回SYN + ACK。

现在服务端能向客户端发 HTTP 响应了！这是最显著的改变，三次握手还没建立，仅仅验证了 Cookie 的合法性，就可以返回 HTTP 响应了。
当然，客户端的ACK还得正常传过来，不然怎么叫三次握手嘛。

**注意**: 客户端最后握手的 ACK 不一定要等到服务端的 HTTP 响应到达才发送，两个过程没有任何关系。

### TFO 的优势
TFO 的优势并不在与首轮三次握手，而在于后面的握手，在拿到客户端的 Cookie 并验证通过以后，可以直接返回 HTTP 响应，充分利用了1 个RTT(Round-Trip Time，往返时延)的时间提前进行数据传输，积累起来还是一个比较大的优势。

## 超时重传机制
TCP 具有超时重传机制，即间隔一段时间没有等到数据包的回复时，重传这个数据包。

重传间隔也叫做**超时重传时间(Retransmission TimeOut, 简称RTO)**，它的计算跟上一节提到的 RTT 密切相关。这里我们将介绍两种主要的方法，一个是经典方法，一个是标准方法。

### 经典方法
经典方法引入了一个新的概念——SRTT(Smoothed round trip time，即平滑往返时间)，每产生一次新的 RTT. 就根据一定的算法对 SRTT 进行更新.这个算法的局限，就是在 RTT 稳定的地方表现还可以，而在 RTT 变化较大的地方就不行了

### 标准方法
为了解决经典方法对于 RTT 变化不敏感的问题，后面又引出了标准方法，也叫Jacobson / Karels 算法。这个公式在 SRTT 的基础上加上了最新 RTT 与它的偏移，从而很好的感知了 RTT 的变化，这种算法下，RTO 与 RTT 变化的差值关系更加密切。

## 流量控制
对于发送端和接收端而言，TCP 需要把发送的数据放到**发送缓存区**, 将接收的数据放到**接收缓存区**。

而流量控制索要做的事情，就是在通过接收缓存区的大小，控制发送端的发送。如果对方的接收缓存区满了，就不能再继续发送了。

# http
## 报文结构
对于 TCP 而言，在传输的时候分为两个部分:TCP头和数据部分。HTTP类似，是一个类似header + body的结构，具体来讲是：
```
起始行 + 头部 + 空行 + 实体
```

- 请求报文例子
```
POST /search HTTP/1.1   // 起始行 （如果是get的话这里会很长，包含数据的url都在这）
Accept: ...             // 头部
Accept-Language: ...
Accept-Encoding: ...
Connection: Keep-Alive  
Cookie: ...
                             // 空行
hl=zh-CN&source=hp&q=domety  // (实体 POST中使用，数据不在url里面在这儿)
```

- 响应报文例子
```
HTTP/1.1 200 OK       // 起始行，也叫状态行
Content-Type: ...     // 头部
Content-Length: ...
                      // 空行
＜html＞               // 实体
＜head＞
＜title＞xxx＜/title＞
＜/head＞
＜body＞
＜/body＞
＜/html＞
```

## 请求方法
http/1.1规定了以下请求方法(注意，都是大写):
- GET: 通常用来获取资源
- HEAD: 获取资源的元信息
- POST: 提交数据，即上传数据
- PUT: 修改数据
- DELETE: 删除资源(几乎用不到)
- CONNECT: 建立连接隧道，用于代理服务器
- OPTIONS: 列出可对资源实行的请求方法，用来跨域请求
- TRACE: 追踪请求-响应的传输路径

GET 和 POST 有什么区别？
略

## URI
URI, 全称为(Uniform Resource Identifier), 也就是统一资源标识符，它的作用很简单，就是区分互联网上不同的资源。

![Screen Shot 2021-08-26 at 17.13.12](/assets/Screen%20Shot%202021-08-26%20at%2017.13.12.png)

例子：
```
https://www.baidu.com/s?wd=HTTP&rsv_spt=1
```
这个 URI 中，
- https即scheme部分
- www.baidu.com为host:port部分（注意，http 和 https 的默认端口分别为80、443）
- /s为path部分
- wd=HTTP&rsv_spt=1就是query部分。

### 编码
URI 只能使用ASCII, ASCII 之外的字符是不支持显示的，而且还有一部分符号是界定符，如果不加以处理就会导致解析出错。
因此，URI 引入了编码机制，将所有非 ASCII 码字符和界定符转为十六进制字节值，然后在前面加个%。
如，空格被转义成了%20，三元被转义成了%E4%B8%89%E5%85%83。

## 状态码
- `1xx`: 表示目前是协议处理的中间状态，还需要后续操作。
  - `101 Switching Protocols`: 在HTTP升级为WebSocket的时候，如果服务器同意变更，就会发送状态码 101。

- `2xx`: 表示成功状态。
  - `200 OK`: 是见得最多的成功状态码。通常在响应体中放有数据。
  - `204 No Content`: 含义与 200 相同，但响应头后没有 body 数据。
  - `206 Partial Content`: 顾名思义，表示部分内容，它的使用场景为 HTTP 分块下载和断点续传，当然也会带上相应的响应头字段Content-Range。

- `3xx`: 重定向状态，资源位置发生变动，需要重新请求。
  - `301 Moved Permanently`: 即永久重定向，对应着302 Found，即临时重定向。比如你的网站从 HTTP 升级到了 HTTPS 了，以前的站点再也不用了，应当返回301，这个时候浏览器默认会做缓存优化，在第二次访问的时候自动访问重定向的那个地址。而如果只是暂时不可用，那么直接返回302即可，和301不同的是，浏览器并不会做缓存优化。
  - `304 Not Modified`: 当协商缓存命中时会返回这个状态码。详见浏览器缓存。

- `4xx`: 请求报文有误。
  - `400 Bad Request`: 开发者经常看到一头雾水，只是笼统地提示了一下错误，并不知道哪里出错了。
  - `403 Forbidden`: 这实际上并不是请求报文出错，而是服务器禁止访问，原因有很多，比如法律禁止、信息敏感。
  - `404 Not Found`: 资源未找到，表示没在服务器上找到相应的资源。
  - `405 Method Not Allowed`: 请求方法不被服务器端允许。
  - `406 Not Acceptable`: 资源无法满足客户端的条件。
  - `408 Request Timeout`: 服务器等待了太长时间。
  - `409 Conflict`: 多个请求发生了冲突。
  - `413 Request Entity Too Large`: 请求体的数据过大。
  - `414 Request-URI Too Long`: 请求行里的 URI 太大。
  - `429 Too Many Request`: 客户端发送的请求过多。
  - `431 Request Header Fields Too Large`: 请求头的字段内容太大。

- `5xx`: 服务器端发生错误。
  - `500 Internal Server Error`: 仅仅告诉你服务器出错了，出了啥错咱也不知道。
  - `501 Not Implemented`: 表示客户端请求的功能还不支持。
  - `502 Bad Gateway`: 服务器自身是正常的，但访问的时候出错了，啥错误咱也不知道。
  - `503 Service Unavailable`: 表示服务器当前很忙，暂时无法响应服务。

## 性质和缺点
### HTTP 特点
- 灵活可扩展，主要体现在两个方面。
  - 语义上的自由，只规定了基本格式，比如空格分隔单词，换行分隔字段，其他的各个部分都没有严格的语法限制。
  - 传输形式的多样性，不仅仅可以传输文本，还能传输图片、视频等任意数据，非常方便。
- 可靠传输。HTTP 基于 TCP/IP，因此把这一特性继承了下来。这属于 TCP 的特性，不具体介绍了。
- 请求-应答。也就是一发一收、有来有回， 当然这个请求方和应答方不单单指客户端和服务器之间，如果某台服务器作为代理来连接后端的服务端，那么这台服务器也会扮演请求方的角色。
- 无状态。这里的状态是指通信过程的上下文信息，而每次 http 请求都是独立、无关的，默认不需要保留状态信息。

### HTTP 缺点
- 无状态
所谓的优点和缺点还是要分场景来看的，对于 HTTP 而言，最具争议的地方在于它的无状态。在需要长连接的场景中，需要保存大量的上下文信息，以免传输大量重复的信息，那么这时候无状态就是 http 的缺点了。但与此同时，另外一些应用仅仅只是为了获取一些数据，不需要保存连接上下文信息，无状态反而减少了网络开销，成为了 http 的优点。

- 明文传输
即协议里的报文(主要指的是头部)不使用二进制数据，而是文本形式。这当然对于调试提供了便利，但同时也让 HTTP 的报文信息暴露给了外界，给攻击者也提供了便利。WIFI陷阱就是利用 HTTP 明文传输的缺点，诱导你连上热点，然后疯狂抓你所有的流量，从而拿到你的敏感信息。

- 队头阻塞问题
当 http 开启长连接时，共用一个 TCP 连接，同一时刻只能处理一个请求，那么当前请求耗时过长的情况下，其它的请求只能处于阻塞状态，也就是著名的队头阻塞问题。接下来会有一小节讨论这个问题。

## Accept系列字段
**数据格式**
HTTP 从MIME type取了一部分来标记报文 body 部分的数据类型，这些类型体现在Content-Type这个字段，当然这是针对于发送端而言，接收端想要收到特定类型的数据，也可以用Accept字段。

具体取值：
- text： text/html, text/plain, text/css 等
- image: image/gif, image/jpeg, image/png 等
- audio/video: audio/mpeg, video/mp4 等
- application: application/json, application/javascript, application/pdf, application/octet-stream

**压缩方式**
采取什么样的压缩方式就体现在了发送方的Content-Encoding字段上， 同样的，接收什么样的压缩方式体现在了接受方的Accept-Encoding字段上。这个字段的取值有下面几种：
- gzip: 当今最流行的压缩格式
- deflate: 另外一种著名的压缩格式
- br: 一种专门为 HTTP 发明的压缩算法

```
Content-Encoding: gzip  // 发送端
Accept-Encoding: gzip   // 接收端
```

**支持语言**
对于发送方而言，还有一个Content-Language字段，在需要实现国际化的方案当中，可以用来指定支持的语言，在接受方对应的字段为Accept-Language。
```ts
Content-Language: zh-CN, zh, en   // 发送端
Accept-Language: zh-CN, zh, en    // 接收端
```

**字符集**
最后是一个比较特殊的字段, 在接收端对应为Accept-Charset，指定可以接受的字符集，而在发送端并没有对应的Content-Charset, 而是直接放在了Content-Type中，以charset属性指定。
```ts
Content-Type: text/html; charset=utf-8  // 发送端
Accept-Charset: charset=utf-8           // 接收端
```

总结图: 左边是服务端，右边是客户端
![Screen Shot 2021-08-26 at 17.25.55](/assets/Screen%20Shot%202021-08-26%20at%2017.25.55.png)

## 传输
- 定长包体：发送端（服务端）在传输的时候一般会在头部带上`Content-Length: xxx`, 来指明包体的长度。如果实际传输的内容大于这个值，多出的部分会自动被截掉。
- 不定长包体：发送端（服务端）头部设置`Transfer-Encoding: chunked`，然后分段传输。这样有两个效果：Content-Length 字段会被忽略，会基于长连接`keep-alive`持续推送动态内容。
- 大文件的传输：采取了范围请求的解决方案，允许客户端仅仅请求一个资源的一部分。前提是服务器要支持范围请求，要支持这个功能，就必须加上这样一个响应头: `Accept-Ranges: none`

范围请求的一个返回报文例子：
```
HTTP/1.1 206 Partial Content
Content-Length: 10
Accept-Ranges: bytes
Content-Range: bytes 0-9/100

data xxxxx
```
多段数据的情况
```
HTTP/1.1 206 Partial Content
Content-Type: multipart/byteranges; boundary=00000010101
Content-Length: 189
Connection: keep-alive
Accept-Ranges: bytes

--00000010101
Content-Type: text/plain
Content-Range: bytes 0-9/96

data xxxxx
--00000010101
Content-Type: text/plain
Content-Range: bytes 20-29/96

hahahah wwwww
--00000010101--
```

## 处理表单数据的提交
表单提交一般是POST请求.有两种主要的表单提交的方式，体现在两种不同的Content-Type取值:

**application/x-www-form-urlencoded**
- 其中的数据会被编码成以&分隔的键值对
- 字符以URL编码方式编码。

转换过程
```
{ a: 1, b: 2 }
=> a=1&b=2
=> a%3D1%26b%3D2 (最终形式)
```

**multipart/form-data**
- 请求头中的Content-Type字段会包含boundary，且boundary的值由浏览器默认指定。
比如
```
Content-Type: multipart/form-data;boundary=----WebkitFormBoundaryRRJKeWfHPGrS4LKe
```
- 数据会分为多个部分，每两个部分之间通过分隔符来分隔，每部分表述均有 HTTP 头部描述子包体，如Content-Type，在最后的分隔符会加上--表示结束。

例子
```
Content-Disposition: form-data;name="data1";
Content-Type: text/plain
data1
----WebkitFormBoundaryRRJKeWfHPGrS4LKe
Content-Disposition: form-data;name="data2";
Content-Type: text/plain
data2
----WebkitFormBoundaryRRJKeWfHPGrS4LKe--
```

multipart/form-data 格式最大的特点在于:每一个表单元素都是独立的资源表述。另外，你可能在写业务的过程中，并没有注意到其中还有boundary的存在，如果你打开抓包工具，确实可以看到不同的表单元素被拆分开了，之所以在平时感觉不到，是以为浏览器和 HTTP 给你封装了这一系列操作。

在实际的场景中，对于图片等文件的上传，基本采用multipart/form-data而不用application/x-www-form-urlencoded，因为没有必要做 URL 编码，带来巨大耗时的同时也占用了更多的空间。

## 队头阻塞问题
HTTP 传输是基于请求-应答的模式进行的，报文必须是一发一收，里面的任务被放在一个任务队列中串行执行，一旦队首的请求处理太慢，就会阻塞后面请求的处理。这就是著名的HTTP队头阻塞问题。

### 解决方案
**并发连接**
对于一个域名允许分配多个长连接，那么相当于增加了任务队列，不至于一个队伍的任务阻塞其它所有任务。在RFC2616规定过客户端最多并发 2 个连接，不过事实上在现在的浏览器标准中，这个上限要多很多，Chrome 中是 6 个。
但其实，即使是提高了并发连接，还是不能满足人们对性能的需求。

**域名分片**
一个域名不是可以并发 6 个长连接吗？那我就多分几个域名。
比如 content1.sanyuan.com 、content2.sanyuan.com。
这样一个sanyuan.com域名下可以分出非常多的二级域名，而它们都指向同样的一台服务器，能够并发的长连接数更多了，事实上也更好地解决了队头阻塞的问题。

## Cookie
HTTP 是一个无状态的协议，每次 http 请求都是独立、无关的，默认不需要保留状态信息。但有时候需要保存一些状态，怎么办呢？

HTTP 为此引入了 Cookie。Cookie 本质上就是浏览器里面存储的一个很小的文本文件，内部以键值对的方式来存储。向同一个域名下发送请求，都会携带相同的 Cookie，服务器拿到 Cookie 进行解析，便能拿到客户端的状态。

服务端可以通过响应头中的Set-Cookie字段来对客户端写入Cookie。比如：
```
// 请求头
Cookie: a=xxx;b=xxx

// 响应头
Set-Cookie: a=xxx
set-Cookie: b=xxx
```

### 生存周期
Cookie 的有效期可以通过Expires和Max-Age两个属性来设置。
- Expires即过期时间
M- ax-Age用的是一段时间间隔，单位是秒，从浏览器收到报文开始计算。

若 Cookie 过期，则这个 Cookie 会被删除，并不会发送给服务端。

### 作用域
关于作用域也有两个属性: Domain和path, 给 Cookie 绑定了域名和路径，在发送请求之前，发现域名或者路径和这两个属性不匹配，那么就不会带上 Cookie。对于路径来说，/表示域名下的任意路径都允许使用 Cookie。

### 安全相关
- 如果带上Secure，说明只能通过 HTTPS 传输 cookie。
- 如果 cookie 字段带上HttpOnly，那么说明只能通过 HTTP 协议传输，不能通过 JS 访问，这也是预防 XSS 攻击的重要手段。
- 相应的，对于 CSRF 攻击的预防，也有SameSite属性。SameSite可以设置为三个值:
  - 在Strict模式下，浏览器完全禁止第三方请求携带Cookie。比如请求sanyuan.com网站只能在sanyuan.com域名当中请求才能携带 Cookie，在其他网站请求都不能。
  - 在Lax模式，就宽松一点了，但是只能在 get 方法提交表单况或者a 标签发送 get 请求的情况下可以携带 Cookie，其他情况均不能。
  - 在None模式下，也就是默认模式，请求会自动携带上 Cookie。

### Cookie的缺点
- 容量缺陷。Cookie 的体积上限只有4KB，只能用来存储少量的信息。
- 性能缺陷。Cookie 紧跟域名，不管域名下面的某一个地址需不需要这个 Cookie ，请求都会携带上完整的 Cookie，这样随着请求数的增多，其实会造成巨大的性能浪费的，因为请求携带了很多不必要的内容。但可以通过Domain和Path指定作用域来解决。
- 安全缺陷。由于 Cookie 以纯文本的形式在浏览器和服务器中传递，很容易被非法用户截获，然后进行一系列的篡改，在 Cookie 的有效期内重新发送给服务器，这是相当危险的。另外，在HttpOnly为 false 的情况下，Cookie 信息能直接通过 JS 脚本来读取。

## HTTP 代理
HTTP 是基于请求-响应模型的协议，一般由客户端发请求，服务器来进行响应。

当然，也有特殊情况，就是代理服务器的情况。引入代理之后，作为代理的服务器相当于一个中间人的角色，具有双重身份:
- 对于客户端而言，表现为服务器进行响应
- 而对于源服务器，表现为客户端发起请求

### 代理服务器的功能
**负载均衡。**
客户端的请求只会先到达代理服务器，后面到底有多少源服务器，IP 都是多少，客户端是不知道的。因此，这个代理服务器可以拿到这个请求之后，可以通过特定的算法分发给不同的源服务器，让各台源服务器的负载尽量平均。当然，这样的算法有很多，包括随机算法、轮询、一致性hash、LRU(最近最少使用)等等。

**保障安全。**
利用心跳机制监控后台的服务器，一旦发现故障机就将其踢出集群。并且对于上下行的数据进行过滤，对非法 IP 限流，这些都是代理服务器的工作。

**缓存代理。**
将内容缓存到代理服务器，使得客户端可以直接从代理服务器获得而不用到源服务器那里。

### 相关头部字段
**Via**
代理服务器需要标明自己的身份，在 HTTP 传输中留下自己的痕迹，就可以通过Via字段来记录。Via中记录的顺序即为在 HTTP 传输中报文传达的顺序。

例子：
```
客户端 -> 代理1 -> 代理2 -> 源服务器

// 在源服务器收到请求后，会在请求头拿到这个字段:
Via: proxy_server1, proxy_server2

// 而源服务器响应时，最终在客户端会拿到这样的响应头:
Via: proxy_server2, proxy_server1
```

**X-Forwarded-For**
字面意思就是为谁转发, 它记录的是请求方的IP地址(注意，和Via区分开，X-Forwarded-For记录的是请求方这一个IP)。这意味着每经过一个不同的代理，这个字段的名字都要变
- 从客户端到代理1，这个字段是客户端的IP
- 从代理1到代理2，这个字段就变为了代理1的 IP

但是这会产生两个问题:
- 意味着代理必须解析 HTTP 请求头，然后修改，比直接转发数据性能下降。
- 在 HTTPS 通信加密的过程中，原始报文是不允许修改的。

**解决方法：** 由此产生了代理协议，一般使用明文版本，只需要在 HTTP 请求行上面加上这样格式的文本即可, 不需要直接修改请求头。
```
// PROXY + TCP4/TCP6 + 请求方地址 + 接收方地址 + 请求端口 + 接收端口
PROXY TCP4 0.0.0.1 0.0.0.2 1111 2222
GET / HTTP/1.1
...
```

**X-Real-IP，X-Forwarded-Host，X-Forwarded-Proto**
分别是获取用户真实 IP，域名，协议名 的字段，不管中间经过多少代理，这个字段始终记录最初的客户端的IP。



# 浏览器相关
## V8的优化
### parse的执行流程
lexer也叫scanner
![Screen Shot 2021-07-30 at 15.51.07](/assets/Screen%20Shot%202021-07-30%20at%2015.51.07.png)

### JIT混合引擎
JS源代码经过了词法分析和语法分析这两个步骤，转成了字节码，其实就是经过任何一门程序语言必经的步骤：**编译**。但是不同于C++的**编译执行**(会先对bytecode进行优化），JS编译结束之后，并不会生成存放在内存或者硬盘之中的目标代码或可执行文件。生成的指令字节码Bytecode，会被立即被JSCore这台虚拟机进行逐行**解释执行**。运行指令字节码（ByteCode）是JS引擎中很核心的部分，各家JS引擎的优化也主要集中于此。

在 V8 出现之前，所有的 JavaScript 虚拟机所采用的都是解释执行的方式，这是 JavaScript 执行速度过慢的一个主要原因（没有编译执行做的优化）。而 V8 率先引入了 **即时编译（JIT）** 双轮驱动的设计。这是一种权衡策略，混合编译执行和解释执行这两种手段，给 JavaScript 的执行速度带来了极大的提升。

思路类似于用同构渲染优化SPA，就是在需要的时候做A，不需要的时候做B，而不是极端的A（SSR）或者极端的B（SPA）。就是在需要的时候优化代码，做**编译执行**，在不需要的时候，直接**解释执行**。

![Screen Shot 2021-07-30 at 15.56.16](/assets/Screen%20Shot%202021-07-30%20at%2015.56.16.png)

### JIT具体流程
Parser 将 JS 源码转换为 AST，然后 Ignition 将 AST 转换为 Bytecode，最后 TurboFan 将 Bytecode 转换为经过优化的 Machine Code(实际上是汇编代码)。
- 如果函数没有被调用，则 V8 不会去编译它。
- 如果函数只被调用 1 次，则 Ignition 将其编译 Bytecode 就直接解释执行了。TurboFan 不会进行优化编译，因为它需要 Ignition 收集函数执行时的类型信息。这就要求函数至少需要执行 1 次，TurboFan 才有可能进行优化编译。
- 如果函数被调用多次，则它有可能会被识别为`热点函数`，且 Ignition 收集的类型信息证明可以进行优化编译的话，这时 TurboFan 则会将 Bytecode 编译为 Optimized Machine Code（优化的机器码），以提高代码的执行性能。

图片中的红色虚线是逆向的，也就是说 Optimized Machine Code 会被还原为 Bytecode，这个过程叫做 「Deoptimization」。这是因为 Ignition 收集的信息可能是错误的，比如 add 函数的参数之前是整数，后来又变成了字符串。生成的 Optimized Machine Code 已经假定 add 函数的参数是整数，那当然是错误的，于是需要进行 Deoptimization。

比如：
```ts
function add(x, y) {
  return x + y;
}

add(1, 2);
add('1', '2');
```

![Screen Shot 2021-07-30 at 15.56.24](/assets/Screen%20Shot%202021-07-30%20at%2015.56.24.png)

## references
- https://juejin.cn/post/6844904100035821575#heading-100
- https://juejin.cn/post/6844904070889603085